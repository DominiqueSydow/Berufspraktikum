#---------------------------------------------------------------------------------------------#
#Purpose:
#    to parse through the result-files and the qgram-files generated by 'probe-generator'
#    in order to find sequences in q-gram-files which do not appear in the match-list (between pattern and genome) generated by 'probe-generator'
#
#Authors:#    Martin Seeger, Matthias Schade
#---------------------------------------------------------------------------------------------#

import os
from dircache import listdir
from os.path import join
import collections
import pickle
import shelve
import math
from matplotlib import pyplot as PLT #import matplotlib.pylab as pl #import pylab as pl
import re
import numpy as np
from scipy.stats import gaussian_kde
#import scipy.stats
import Tkinter
#from Tkinter import *
import tkFileDialog

#from Bio import SeqIO
from Bio import Entrez
import datetime
from Bio.Blast import NCBIWWW
from Bio.Blast import NCBIXML
#from collections import OrderedDict
#import pprint
#import pickle
#from time import sleep

#http://www.patentlens.net/daisy/influenza/4133/3929.html
#---------------------------------------------#
# CONSTANTS
#---------------------------------------------#
#Create artificial q-gram-list listing all probes of length n from a particular virus segment
#qgramindexlist = range(0, 1000)

#Input folders:
#    -from the pattern (e.g. virus) a list of n-grams is created to be matched against the genome (e.g. host)
#    -the genome is used for targeting each of the n-grams against
# attention: switch "\" by "/" due to OS

folder_pattern = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/pattern/"
folder_genome = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/genome/"
#folder_pattern = "D:/Data/Matthias Schade/workspace/VirusProbeDesign/pattern"
#folder_genome = "D:/Data/Matthias Schade/workspace/VirusProbeDesign/genome"

#folder from which results are read; if input_folder="" then the current working directory is chosen instead
#input_folder = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/mm4/2012-06-05_13-05_19nt"
input_folder = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/mm4/2012-06-05_13-05_19nt/"
#input_folder = "D:/Data/Matthias Schade/workspace/VirusProbeDesign/2012-06-04_12-25_20nt/"
#input_folder = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/2012-06-03_22-06_17nt/"

#Filter: name-ending of files containing original qgrams:
filter_qgramfileFA = "_qgrams.fa"
#filter_qgramfileFA = "_qgrams.fa"

#Filter: name-ending of files containing results of razerS-alignment (where pattern matches with target genome):
filter_results = ".result"


#Analysis saving name
fname_pPP = "pPP"
picForm = ".dat"

#output file with found sequences:
outFA = "SequencesFound"
outForm = ".fa"

#Shelve file name for loading all variables from output-folder
shlv_name = "shelved.out" #taken from: http://stackoverflow.com/questions/2960864/how-can-i-save-all-the-variables-in-the-current-python-session

#Segs: 1=PB2(2300), 2=PB1(2300), 3=PA(2193), 4=HA(1723), 5=NP(1501), 6=NA(1373), 7=MP(986), 8=NS(848)
seg_length={"seg1": 2300, "seg2":2300, "seg3":2193, "seg4":1723, "seg5":1501, "seg6" :1373, "seg7":986, "seg8":848 } #reference segment length

#Allow code to be run in two modi: 
#    either all sequences found by razerS will be kept ('false')
#    or all sequences foudn by razerS will be considered negative hits, such that they will be cleaned from 
#     the entire qGram-Lists and the remaining hits will be the qGram-Entries which did not get purged.
bNonMatchFinder = True  #true = primary results will be purged by hits in genome  (=> inversion of results)
                        #false = primary hits in genome will be considered hits   (=> keeping of results)

#(Dis/)Enable checking the resulting sequences via BLAST against an organism:
resultCheckViaNCBI = True

#
#Entrez.email = "matthiasschade.de@googlemail.com" #necessary??? (only executed for: resultCheckViaNCBI=True)
#Host Genome : http://www.ncbi.nlm.nih.gov/genome/seq/BlastGen/BlastGen.cgi?taxid=9615
#seq_H = ""      #full sequence if available
#seq_H_taxid = 9615 #taxonomy identifier
#BLAST_orgn="Canis familiaris[orgn]" #(only executed for: resultCheckViaNCBI=True)
BLAST_orgn="Canis familiaris" #(only executed for: resultCheckViaNCBI=True)

#BLAST-algorithm used (only executed for: resultCheckViaNCBI=True)
BLAST_algr = "blastn"

#BLAST-database used (only executed for: resultCheckViaNCBI=True)
#    large: "nt", "genbank", 
#    dog: "9615_genomic" (dog genomic), "dog_9615" (SNP database for dog),
#    human: "9606_genomic" (human genomic)
BLAST_db = "nt"

#Histlist_size returned by blast from query (only executed for: resultCheckViaNCBI=True)
qHitSize = 5

#required minimum identity for BLAST-verification hit to be returned (only executed for: resultCheckViaNCBI=True)
#ident #qPerIdent = 90

#Rejection criterion: how many mismatches allowed
#nMM = 2 

#query-result filenames for saving: output format will be ['results_file'####.xml] (only executed for: resultCheckViaNCBI=True)
results_file = "test"

#Maximum OS-dependent length of filename (only executed for: resultCheckViaNCBI=True)
maxFileLen=100

#add a delay in between two queries to the internet-database (only executed for: resultCheckViaNCBI=True)
queryDelay=2 #sleeps for x seconds

#TestStrings
testBLAST_ExpectPositive = "GTTAATGTAGCTTAATTA" #this string must result in a perfect match!!!
testBLAST_ExpectNegative = "GGATTCGAACCGAACGGC" #this string must result in very bad match!!!


def create_qgramIndex_list(allfiles, input_folder):
    #qgramindexlist=[]
    qgramindexlist={}
    m=0
    #User feedback
    print "\nSTARTING: Creation of qgramIndexList for all source patterns ..."
    #get a list of all files in the current working directory of python
    #allfiles = listdir(os.getcwd())

    for myFile in allfiles:
        #consider only those files which end the filter-string specified
        if not myFile.endswith(filter_qgramfileFA): continue
        #open each file as "read only"
        
        myFilePath = join(input_folder, myFile)
        print " opening: ", myFilePath
        with open(myFilePath, "r") as f:
            m=m+1
            #print "reading in ", myFile
            for line in f:
                #print "length: ", len(qgramindexlist)
                #in each file and each line get the first 'word' only 
                #print "linsplit: ", line.split()
                firstword = line.split()[0]
                #print "firstword: ", firstword
                #print "firstword[ohne ersten Buchstaben]: ", firstword[1:]
                #
                if firstword[0]==">":
                    strPos = firstword[1:] #Zwischenspreichern
                else:
                    strSeq = firstword[1:] #Zwischenspeichern
                    #print len(qgramindexlist)
                    #print "strPos: ", strPos, "strSeq: ", strSeq
                    #qgramindexlist.append((strPos, strSeq))
                    qgramindexlist[strPos] = strSeq
                    strPos=""
                    strSeq=""
    print " DONE: qgramIndexList completed for "+str(m)+" file(s), containing a total of " + str(len(qgramindexlist)) +" elements."
    return qgramindexlist

def remove_qGramsByHost(allfiles,input_folder, qGramIndexKeys):
    '''
    Removes all qgrams from qGramIndexKeys which were found to also exist in the host genome
    by parameters (identity, rr) specified for razerS
    '''
    
    nInitial = len(qGramIndexKeys)
    
    #------------------------#
    #User feedback
    #------------------------#
    print "\nSTARTING: Removal of qgrams which were found to also exist in the host genome. Starting with "+str(nInitial)+" qgrams ..."
    resultsIndexKeys=[]
    for myFile in allfiles:
        #consider only those files which end the filter-string specified
        if not myFile.endswith(filter_results): continue
        #open each file as "read only"
        myFilePath = join(input_folder, myFile)
        with open(myFilePath, "r") as f:
            #print "reading in ", myFile
            for line in f:
                #print "length: ", len(qgramindexlist)
                #in each file and each line get the first 'word' only 
                #print "linsplit: ", line.split()
                firstword = line.split()[0]
                #ignore comments which appear, when for the output of razerS the flag "-a" was set
                if firstword[1]!="#":
                    resultsIndexKeys.append(firstword)
    #reduce results down to unique entries
    resultSet = set(resultsIndexKeys) 
    #remove sequences from the qgramindex, leaving only those sequences for which raszers did not return a match between virus and host-genome
    #print "qGramIndexKeys before: ", len(qGramIndexKeys)
    #print "resultSet before: ", len(resultSet)
    #print "qGramIndexKeys before: ", qGramIndexKeys
    #print "resultSet before: ", resultSet
    qGramIndexKeys = qGramIndexKeys-resultSet
    #print "qgramindexlist after: ", len(qGramIndexKeys)

    #------------------------#
    #User feedback
    #------------------------#  
    nEnd = len(qGramIndexKeys)
    print " DONE: "+str(nInitial-nEnd)+" qgrams removed, leaving "+str(nEnd)+" qgrams."
    
    return list(qGramIndexKeys)


def find_key(dic, val):
    """return the key of dictionary dic given the value"""
    #COMMENT: actually, positive case (existance of multiples) never tested!!!!
    return [k for k, v in dic.iteritems() if v == val][0]


def get_multipleHitsInPattern(qGramIndexDict):
    #COMMENT: actually, positive case (existance of multiples) never tested!!!!
    multiSeqPos=[]
    print "\nSTARTING: Checking for sequence-doubles or -multiples in source pattern."
    #extract all sequences from dict
    seqList = qGramIndexDict.values()
    if len(seqList)> len(set(seqList)):
        print "\tSequence-doubles or -multiples found. Extracting sequences ..."
        #create statistic on occurrences of values in list
        y=collections.Counter(seqList)
        #sequences, which occur more than once
        multiSeqs = [i for i in y if y[i]>1]
        print "\t " +str(len(multiSeqs))+" sequences occur more than once."
        #Positions of sequences which occur more than once
        #multiSeqPos = [j in qGramIndexDict ]
        multiSeqPos = find_key(qGramIndexDict, multiSeqs)
        print "\t Corresponding positions: ",  multiSeqPos
    else:
        print " DONE: No sequence-doubles or -multiples found."    

    return multiSeqPos



def get2DArrayOfNonHitsInTargetGenome(qGramIndexDict,input_folder):
    #DESCIPTION: returns a 2D-array: for each source pattern the is a list of non-hits
    # e.g.: {[segment1: (452, 578, 323, 676)], [segment4: (2, 676)]}
    
    positiveProbePositions = {}
    
    #Read in all files in the patter directory
    #patternfiles = listdir(folder_pattern)
    patternfiles = listdir(input_folder)
    #_qgrams.fa
    #print "patternfiles", patternfiles
    
    #strip file-type ending
    #patternFileNames = [x[:-3] for x in patternfiles: if not x.endswith(".fa"): continue] 
    pFN=[]
    for x in patternfiles: #TODO: pythonic!!!!
        if x.endswith(filter_qgramfileFA): #TODO: pythonic!!!!
            #pFN.append(x[:-len(filter_qgramfileFA)]) #TODO: pythonic!!!!
            pFN.append(x[:4]) #TODO: pythonic!!!!
    patternFileNames = pFN #TODO: pythonic!!!!
    
    ##        if not resultfile.endswith(".result"): continue
    #print "patternfileNames: ", patternFileNames
    
    #print "-----PATTTERN FILE NAMES\n"
    #print patternFileNames
    
    #------------------------#
    #User feedback
    #------------------------#
    print "\nSTARTING: extracting probe-starting-positions relative to source pattern for each source pattern."
    #print "len(qGramIndexDict): ", len(qGramIndexDict)
    for p in patternFileNames:
        miniSeqP = []
        
        
        for q in qGramIndexDict:
            #print "q: ", q
            #print "patternfileNames: ", p
            #print "q.find(patternfileNames): ", q.find(p)
            
            #print "p: ", p, " and q: ", q
            #print "q.find(p)", q.find(p)
            
            #only if the pattern name can be identified:
            if (q.find(p)>-1):
                #get the sequence position, which is walled in between "(" and ":":
                mySubString=q[q.find("(")+1:q.find(":")]
                #append position
                miniSeqP.append(int(mySubString))
                #print "mySubString: ", mySubString
                
                #print str(q(srt:end))
                #seqPosition.append(int(q(srt:end)))
        #flush sequence positions into larger "array"
        miniSeqP.sort()
        
        positiveProbePositions[p]=miniSeqP
    
    print " DONE: extracting probe starting positions."
    
    return positiveProbePositions

def loadpPP(fname,picForm):
    #DESCRIPTION:
    #    load settings as a pickle from a specified filename
    print "STARTING: loading pPP"
    pPP ={}
    try:
        fileobj = open(fname+picForm,'r')
        pPP = pickle.load(fileobj)
        fileobj.close()
    except Exception:
        print " ERROR: loading results failed."
    print " DONE: loading pPP"
    return pPP

def savepPP(pPP,input_folder, fname, picForm):
    #DESCRIPTION: store settings as a pickle under a specified filename
    print "\nSTARTING: saving results"
    fname = join(input_folder, fname)
    try:
        fileobj = open (fname+picForm,'w')
        success = pickle.dump(pPP,fileobj)
        fileobj.close()
    except Exception:
        print " ERROR: saving results failed."
    
    print " DONE: Results saved as: "+ fname
    
    return success

def visualizepositiveProbePositions(pPP, q, mm, rr, ident):
    
    #error check
    if not type(pPP) is dict:
        print " Input not of type dict"
        return
    
    #User-feedback
    print "\nSTARTING: visualization"
    
    #number of columns and rows for subplot
    plot_cols = 2
    l = len(pPP)
    plot_lins = int(math.ceil(l/plot_cols))
    
    #get screen width and height
    root = Tkinter.Tk()
    screen_width = root.winfo_screenwidth()
    screen_height = root.winfo_screenheight()
    
    #run through all output lines in positivePatternPositions (pPP):
    figFlag=0
    ax=[]
    c=0
    for o in pPP:
        c=c+1 # counter for subplot
        
        #jump to the next segment, if this one is empty
        #if not pPP[o]:
            #print "will continue" 
            #continue
        
        x=pPP[o]
        y=[]
        xLim=[0,2500]
        yLim=[0.9,1.1]
        #create a y for every x
        y = [1 for i in x]
        #for i in x: #y =[1 for i in x] more pythonic????
        #    y.append(1)
        #print "\nSegment: ", o
        #print "Data: ", y
        
        #create a figure once (only once, so set a flag!) into which subplots are projected
        if figFlag==0: 
            #fig = PLT.figure() #creates a new fig
            fig = PLT.figure(figsize=(14, 14)) #creates a new canvas with width, height in inches
            #fig = PLT.figure(figsize=(screen_width, screen_height)) #creates a new canvas with width, height in inches
            str_title = "APR8 sequence starting positions for probe with "+str(q)+" nt length at an edit distance of "+str(mm+1)+ " (ident="+str(ident)+") or higher against canis familiaris genome"
            
            #differentiate between match/ and non-match finding
            if bNonMatchFinder:
                str_title = "NonMatchFinder: " + str_title
            else:
                str_title = "MatchFinder: " + str_title
            fig.suptitle(str_title)
            figFlag=1
        
        #--------------------------------------------
        #create a subplot:
        #--------------------------------------------
        #matplotlib.pyplot.subplots(nrows=1, ncols=1, sharex=False, sharey=False, squeeze=True, subplot_kw=None, **fig_kw)
        #sharex : bool
        # If True, the X axis will be shared amongst all subplots. If True and you have multiple rows, the x tick labels on all but the last row of plots will have visible set to False
        #sharey : bool
        # If True, the Y axis will be shared amongst all subplots. If True and you have multiple columns, the y tick labels on all but the first column of plots will have visible set to False
        
        sollPos = re.findall(r'\d+', o) #extract integers from key-name for correct positioning        
        if sollPos:
            #print sollPos
            if int(sollPos[0])>0:
                ax.append(fig.add_subplot(420+int(sollPos[0]))) #211
        else:
            ax.append(fig.add_subplot(420+c)) #211
            
        ax[len(ax)-1].scatter(x,y, marker='+')#edgecolors='none', alpha=0.2)
        ax[len(ax)-1].set_xlim(xLim)
        ax[len(ax)-1].set_ylim(yLim)
        ax[len(ax)-1].set_title(o)

        
        #Visualize density distribution (normed to 1) of positive sequences
        if len(y)>1:
            x[0]=x[0]*1.0001 #attention: multiplicator needed ... otherwise no conversion from int to float thus causing the density estimation to fail
            density = gaussian_kde(x) #density = scipy.stats.kde.gaussian_kde(x)
            density.covariance_factor = lambda : 0.05
            density._compute_covariance()
            xg = np.arange(0., max(xLim), 1) #0.1
            denMax=max(density(xg))
            #ax[len(ax)-1].plot(xg, density(xg)/denMax, 'k:', alpha=0.3) #alpha=0.1
            ax[len(ax)-1].plot(xg, density(xg)* ((max(yLim)-min(yLim))/denMax) + min(yLim), 'k:', alpha=0.3) # shift density curvoonto min-displayed
        
        #Create a text-insert:
        font = "sans-serif"
        ax[len(ax)-1].text(max(xLim)*0.85,max(yLim)*0.95, str(len(x))+" seqs", ha="center", family=font, size=14)
        
        if sollPos:
            #print sollPos
            if int(sollPos[0])>0:
                #symbolysing segment length: draw a green box that spans the y-axis
                #ax[len(ax)-1].axvspan(1.25, 1.55, facecolor='g', alpha=0.5)
                ax[len(ax)-1].axvspan(0, seg_length[o], facecolor='g', alpha=0.1)
                #seg_length
    
    # show the plot on the screen
    #PLT.show()
    
    
    #save plot in input_folder
    strSaveFig = join(input_folder, 'output_img.png')
    PLT.savefig(strSaveFig)
    print " saving plot in ", strSaveFig
    
    #User Feedback
    print " DONE: visualization\n"
    return

def extract(d, keys):
    # from Trent Mick: http://code.activestate.com/recipes/115417-subset-of-a-dictionary/
    return dict((k, d[k]) for k in keys if k in d)

def getUserFolder(str_iniDir, strDialog):
    if not str_iniDir:
        str_iniDir = os.getcwd()
        print "hihi"
    master = Tkinter.Tk()
    master.withdraw() #hiding tkinter window
    #"Open pattern directory"
    #file_path = tkFileDialog.askopenfilename(initialdir=folder_pattern, title="Open pattern file", filetypes=[("txt file",".txt"),("All files",".*")])
    file_path = tkFileDialog.askdirectory(initialdir=str_iniDir, title=strDialog, mustexist=True)
     
    if file_path != "":
        #print "you chose file with path:", file_path
        str_Return = file_path
    else:
        #print "you didn't open anything!"
        str_Return = str_iniDir
     
    master.quit()
    return str_Return

def purgeByGenome(input_folder, allfiles, qGramIndexDict):
    #this function reduces entries in qGramIndexDict by sequences found in allfiles,
    # such that only those entries in qGramIndexDict remain which were not named/found in allfiles in folder input_folder
    
    #extract only the sequence names (thereby ignoring the sequences) and reduce it to unique entries (probably unnecessary)
    qGramIndexKeys = set(qGramIndexDict.keys()) #qGramIndexListOnly = [qGramIndexListWithSeq[i][0] for i in range(0, len(qGramIndexListWithSeq) -1)]
    
    #from qGramIndexKeys remove all entries which have also been found to exit in the target-genome
    # so 'qGramIndexKeys_purged' only contains suitable positive probe target sequences
    qGramIndexKeys_purged = remove_qGramsByHost(allfiles, input_folder, qGramIndexKeys)
    
    #reduce dict down to the remaining suitable probe-target sequences
    #qGramPositiveIndex = {} # will contain suitable probe-target sequences
    qGramPositiveIndex = extract(qGramIndexDict, qGramIndexKeys_purged)
    
    return qGramPositiveIndex

def getShelvedData(input_folder, shlv_name):
    # Retrieving Objects from a Shelve File and thereby overriding current global variables
    
    #Variables to load from shelve-file: initialized in case shelve-file failed to load
    v = -1  #default-value
    mm=-1 #default-value
    rr=-1 #default-value
    q=-1    #default-value
    ident=-1#default-value
    razers_arg = [] #default-value
    patternfiles = [] #default-value
    genomefiles = [] #default-value
    
    shelve_file = join(input_folder, shlv_name)
    if os.path.exists(shelve_file):
        print "\nSTARTING to load variables from shelve-file: ", shelve_file
        my_shelve = shelve.open(shelve_file, "r")
        #cc = 0
        #for k in my_shelve.keys():
        #    cc = cc + 1
        #    obj = my_shelve[k]
        #if cc == len(my_shelve):
        #    print "yeah, lag richtig: ", len(my_shelve)
            
        if len(my_shelve) > 0:
            v = my_shelve['v'] #get version number
            mm = my_shelve['mm'] #get number of mismatches
            rr = my_shelve['rr'] # get recognition-ration for checking against genome
            q = my_shelve['q'] # get probe length tested
            ident = my_shelve['ident']
            razers_arg = my_shelve['razers_arg']
            try:
                patternfiles = my_shelve['patternfiles'] # original list of pattern files used # WHY DONT THESE LOAD???
                genomefiles = my_shelve['genomefiles'] # original list of genome files used # WHY DONT THESE LOAD???
            except Exception: 
                print " exception thrown and passed"
                pass
            print " DONE: Variables loaded successfully from shelve file"
        else:
            print " DONE: No variables loaded from shelve file; continuing with default values"
        my_shelve.close()
    else:
        print " No shelve-file found, thus no variables loaded from shelve file; continuing with default values"
    return v, q, mm, rr, q, ident, razers_arg, patternfiles, genomefiles

def createFoundSequenceFileFA(qGramPositiveIndex,folder, FName):
    myFile = join(folder, FName)
    readcount = 0
    #open/create file as writable
    with open(myFile, 'w') as f:
        #create one fasta-entry
        for s in qGramPositiveIndex:
            #f.write(">read_" + str(readcount)) #TODO: subsitute with 'qgram_entryname'
            #f.write(">source " + pattern_source+" SequencePos "+posStrList[readcount]) 
            #f.write(">source__" + pattern_source+"("+posStrList[readcount]+")")
            f.write(">" + str(s)+"\n")
            f.write(qGramPositiveIndex[s]+"\n")
            readcount += 1
    return myFile

def getBestHSP(blast_records):
    #for the best hit get the number of positive matches
    #return both the best HSP_positive and the number of records checked
    hspMax=0    #best identity hit
    k=0
    try:
        blast_record = blast_records.next()
        for alignment in blast_record.alignments:
            k=k+1
            m=0
            for hsp in alignment.hsps:
                m=m+1
                #print hsp.positives, k, m
                if hsp.positives>hspMax:
                    hspMax=hsp.positives
    except:
        print "the end of checking for HSP."
    #return
    return [hspMax,k]

def saveBLASTasPlainText(blast_records,E_VALUE_THRESH,FName, bVisualize):
    #blast_record: a blast record
    #E_VALUE_THRESH:
    #FName: file anme with path to write results to
    #bVisualize: a flag indicating if visualization should occur 
    

    #check if file exists, if not, create file; finally open file in 'strMod' modus
    #import os.path
    #os.path.isfile(fname)
    print "opening file: FName", FName
    with open(FName, 'a') as f:
        #print "asdf"
        #print "blast_record", blast_record
        #print "blast_record.alignments ", blast_record.alignments
        #print "type(blast_record): ", type(blast_records)
        try:
            blast_record = blast_records.next()
            for alignment in blast_record.alignments:
                for hsp in alignment.hsps:
                    if hsp.expect < E_VALUE_THRESH:
                        f.write('****Alignment****\n')
                        f.write('sequence:' +str( alignment.title) + "\n")
                        f.write('length:' +str(alignment.length) + "\n")
                        f.write('e value:'+str(hsp.expect) + "\n")
                        f.write(hsp.query[0:75] + '...'+'\n')
                        f.write(hsp.match[0:75] + '...'+'\n')
                        f.write(hsp.sbjct[0:75] + '...'+'\n')
                        f.write("\n")
                        #User-Feedback: output to screen
                        if bVisualize:
                            print '****Alignment****'
                            print 'sequence:', alignment.title
                            print 'length:', alignment.length
                            print 'e value:', hsp.expect
                            print hsp.query[0:75] + '...'
                            print hsp.match[0:75] + '...'
                            print hsp.sbjct[0:75] + '...'
                        else:
                            print "bVisualize negative: ", bVisualize
            bsuccess=True
        except:
            print "the end of writing saveBLAST."
            bsuccess=False
    f.close()

    return bsuccess


def checkFAFileViaBLASTAgainstGenome(BLAST_orgn, BLAST_algr, BLAST_db, mySeq, qHitSize, ident, results_file, maxFileLen, queryDelay, t1start, input_folder, n_now, n_total, mySeqName):
    
    #INPUT:
    #    BLAST_orgn: organism to compare 'mySeq' against (eg.:"Canis familiaris[orgn]") 
    #    BLAST_algr: type of search (eg. blastn)
    #    BLAST_db: type of data (eg. "nt")
    #    mySeq: one sequence or a list of sequences??????????
    #    qHitSize: number of hits to be extracted from the answer of the BLAST-query (e.g.: 2)
    #    qPerIdent: required minimum identity for blast hit to be returned
    #    results_file: query-result filenames for saving: output format will be ['results_file'####.xml]
    #    maxFileLen: Maximum length of filename (OS-dependent)
    #    pickle_file: name of file for dumping results as pickle
    #    queryDelay: add a delay in between two queries to the internet-database (
    #    t1start:
    #
    # inspired by: http://scienceoss.com/run-blast-from-biopython/
    #
    
    #User-Feedback    
    if n_now==1:
        print '-------------------------------------------------------------'
        if n_now==1:
            print ' Checking Results by blasting them via NCBI-BLAST  '
        if n_now==0:
            print ' Testrun:  '
        print '-------------------------------------------------------------'
        print
        print 'Input-Parameters'
        print '\tBLAST-Parameters: ', BLAST_algr, BLAST_db, qHitSize, ident, BLAST_orgn
        #print '\tVirus-Genome-Parameters: ', seq_v_file, len(rng_v)
        print '\tProbe-Length (nt): ', len(mySeq)
   
    
    if mySeq:
        nProbeLen = len(mySeq)
        #print "nProbeLen: ", nProbeLen
    else:
        nProbeLen = 0
        print "WARNING: no nProbeLength given"
    
    #User-Feedback:
    print "\t"+str(datetime.datetime.now()), '- - ('+str(n_now)+'/'+str(n_total)+'): Query with(h=', qHitSize, 'i=', ident, ') started for', len(mySeq), 'nt-long sequence: ', mySeq
    
    #QUERY
    #    result_handle = NCBIWWW.qblast("blastn", "nt", q, hitlist_size=5, perc_ident=50, megablast=True, entrez_query="Canis familiaris[orgn]")
    #    result_handle = NCBIWWW.qblast("blastn", "nt", ["ACCCTG", "ACTTCTG"], entrez_query="Canis familiaris[orgn]")
    #    result_handle = NCBIWWW.qblast("blastn", "nt", q)
    result_handle = NCBIWWW.qblast(BLAST_algr, BLAST_db, mySeq, hitlist_size=qHitSize, perc_ident=ident, entrez_query=BLAST_orgn)
    
    #Parse Results
    result_handle.seek(0) # rewind result_handle back to the beginning
    blast_records = NCBIXML.parse(result_handle)
    #print "type(blast_record) 1: ", type(blast_records)
    
    #for the best hit get the number of positive matches
    [hspMax, k] = getBestHSP(blast_records)
    #print "type(blast_record) 2: ", type(blast_records)
    
    #User-Feedback
    if k > 0:
        print "\t"+str(datetime.datetime.now()), '- -     ... resulting in ', k, '/', qHitSize, 'records fulfilling the requirements with best matching-identity of', hspMax, '/', nProbeLen
    else:
        print "\t"+str(datetime.datetime.now()), '- -     ... resulting in 0 records fulfilling the requirements, meaning: this sequence is predicted 100% hybridize a sequence from the specified database.'


    #Calculate missmatch-number
    if k > 0:
        mm = nProbeLen - hspMax # nProbeLen = q?????
    else:
        mm = 0



    #Save the direct results of the BLAST-query into file    
    #Create a filename for results of the current sequence
    if n_now<>0:
        now = datetime.datetime.now()
        if len(mySeq) < maxFileLen:
            saveFName = mySeqName+"_"+str(mySeq + "_vs_" + "__"+str(BLAST_db) + now.strftime("%Y-%m-%d_%H-%M") + ".xml")
        else:
            saveFName = mySeqName+"_"+str(results_file + "__"+now.strftime("%Y-%m-%d_%H-%M") + ".xml")
        saveFName = saveFName.replace(":", "-") #remove ':' from file name

        #save as xml output
        save_file = open(join(input_folder, saveFName), "w") #save_file = open("my_blast.xml", "w")
        result_handle.seek(0) # rewind result_handle back to the beginning
        save_file.write(result_handle.read())
        save_file.close() #close handle for results
                
        #save a plain text file:
        save_file_txt = saveFName[0:-4] + str(".txt") 
        bVisualize=True
        #blast_records.seek(0)
        saveBLASTasPlainText(blast_records,1, join(input_folder, save_file_txt), bVisualize)
        

        
        #result_handle.seek(0) # rewind result_handle back to the beginning
        #saveBLASTasPlainText(result_handle,1, join(input_folder, save_file_txt), bVisualize)
        
    else:
        saveFName=""
    
    #User-Feedback on Results if this is the last one
    if (n_now == n_total & n_now>0):
        print '--------------------------------------------------'
        print 'Total Runtime for',n_total,'queries: ', datetime.datetime.now()-t1start
        print '--------------------------------------------------'
        print
        print 'Input-Parameters'
        print '    BLAST-Parameters: ', BLAST_algr, BLAST_db, qHitSize, ident, BLAST_orgn
        #print '    Virus-Genome-Parameters: ', seq_v_file, len(rng_v)
        print '    Probe-Length (nt): ', len(mySeq)
        print

    
    #Create output dic with
    #    "sequence: occurences in virusgenome, lowest mismatch in hostgenome, results-filename"
    #resultsLs[mySeq] = [qdict[mySeq], mm, saveFName]
    return [mySeq, mm, saveFName]    

#---------------------------------------------#
# MAIN CODE
#---------------------------------------------#
if __name__=="__main__":
    
    #------------------------#
    #User feedback
    #------------------------#
    if bNonMatchFinder:
        print "\n--------------------------------\n   WELCOME to non-match-finder\n--------------------------------\n"
    else:
        print "\n--------------------------------\n   WELCOME to     match-finder\n--------------------------------\n"

    #get Folder to be processed/analysed from user
    input_folder = getUserFolder(input_folder, "Open input folder")
    
    # Retrieving Objects from a Shelve File and thereby overriding current global variables
    v, q, mm, rr, q, ident, razers_arg, patternfiles, genomefiles = getShelvedData(input_folder, shlv_name)
    
    #get a list of all files in the current working directory of python
    allfiles = listdir(input_folder) #alternative: os.getcwd()
    
    #create a full list of all qgrams of all input-patterns
    qGramIndexDict = create_qgramIndex_list(allfiles,input_folder)
    
    #optionally purge 
    if bNonMatchFinder:    
        qGramPositiveIndex = purgeByGenome(input_folder, allfiles, qGramIndexDict)
    else:
        qGramPositiveIndex = qGramIndexDict
        print "\nComment: no purging of razerS results took place"
    
    #check if the current qGramIndexDict contains the same sequence twice
    multipleHitsInPattern = get_multipleHitsInPattern(qGramPositiveIndex)
    #print "\n len(multipleHitsInPattern): ", len(multipleHitsInPattern)
    #print "\n multipleHitsInPattern: ", multipleHitsInPattern

    #write an FASTA-output file
    myF = outFA + str("_%03d_nt" %q)+str("_%03d_mm" %mm)+str("_%03d_rr" %rr)+outForm
    outputFA = createFoundSequenceFileFA(qGramPositiveIndex,input_folder, myF)
        
    #get 2D-array of non-hits for each source pattern
    positiveProbePositions = get2DArrayOfNonHitsInTargetGenome(qGramPositiveIndex,input_folder)    
    

    #print "qGramPositiveIndex: ", qGramPositiveIndex
    
    #print "\n len(Results): ", len(positiveProbePositions)
    #print "\n Results: ", positiveProbePositions
    
    #saving Results before attempting to visualize them
    myF_pPP = fname_pPP + str("_%03d_nt" %q)+str("_%03d_mm" %mm)+str("_%03d_rr" %rr)
    savepPP(positiveProbePositions, input_folder, myF_pPP, picForm)
    
    #create scatter plots for each segment
    visualizepositiveProbePositions(positiveProbePositions, q, mm, rr, ident)
    
    ident=50 #TODO 
    #Check resulting sequences in 'qGramPositiveIndex' via BLAST against an organism:
    if resultCheckViaNCBI:
       
        i=0
        t1start = datetime.datetime.now() #track time consumption
        for myKey in qGramPositiveIndex:
            i=i+1
            #print datetime.datetime.now(), '- - ('+str(i)+'/'+str(len(qGramPositiveIndex))+'): Query with(h=', qHitSize, 'i=', ident, ') started for', len(qGramPositiveIndex[myKey]), 'nt-long sequence: ', qGramPositiveIndex[myKey]
            
            [mySeq, BLASTmm, saveFName] = checkFAFileViaBLASTAgainstGenome(BLAST_orgn, BLAST_algr, BLAST_db, qGramPositiveIndex[myKey], qHitSize, ident, results_file, maxFileLen, queryDelay, t1start, input_folder, i, len(qGramPositiveIndex), myKey)

        
        #Save resultsLs
        #file = open("pickle.pck", "w") # write mode
        #filePCK = open(str(pickle_file)+"_"+str(len(positiveProbePositions[0]))+"nts.pck", "w") # write mode
        #pickle.dump(resultsLs, filePCK)
        
        #Test BLAST-search:
        #Expecting positive results using Teststring named 'testBLAST_ExpectPositive'
        checkFAFileViaBLASTAgainstGenome(BLAST_orgn, BLAST_algr, BLAST_db, testBLAST_ExpectPositive, qHitSize, ident, results_file, maxFileLen, 0, t1start, input_folder, 0, 0, "posTest")
        #Expecting negative results using Teststring named 'testBLAST_ExpectNegative'
        checkFAFileViaBLASTAgainstGenome(BLAST_orgn, BLAST_algr, BLAST_db, testBLAST_ExpectPositive, qHitSize, ident, results_file, maxFileLen, 0, t1start, input_folder, 0, 0, "negTest")
    else:
        print "Variable/flag for checking results via NCBI-BLAST had not been activated."
    