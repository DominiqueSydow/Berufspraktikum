#---------------------------------------------------------------------------------------------#
#Purpose:
#    to parse through the result-files and the qgram-files generated by 'probe-generator'
#    in order to find sequences in q-gram-files which do not appear in the match-list (between pattern and genome) generated by 'probe-generator'
#
#Authors:#    Martin Seeger, Matthias Schade
#---------------------------------------------------------------------------------------------#
#from pprint import pprint
#import copy
import os
from dircache import listdir
from os.path import join
import collections
import pickle
import shelve
import math
from matplotlib import pyplot as PLT #import matplotlib.pylab as pl #import pylab as pl
import re
import numpy as np
from scipy.stats import gaussian_kde
#import scipy.stats
import Tkinter
#from Tkinter import *
import tkFileDialog


#from Bio import SeqIO
from Bio import Entrez
import datetime
from Bio.Blast import NCBIWWW
from Bio.Blast import NCBIXML
#from collections import OrderedDict
#import pprint
#import pickle
#from time import sleep

#http://www.patentlens.net/daisy/influenza/4133/3929.html
#---------------------------------------------#
# CONSTANTS
#---------------------------------------------#
#Create artificial q-gram-list listing all probes of length n from a particular virus segment
#qgramindexlist = range(0, 1000)

#Input folders:
#    -from the pattern (e.g. virus) a list of n-grams is created to be matched against the genome (e.g. host)
#    -the genome is used for targeting each of the n-grams against
# attention: switch "\" by "/" due to OS

folder_pattern = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/pattern/"
folder_genome = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/genome/"
#folder_pattern = "D:/Data/Matthias Schade/workspace/VirusProbeDesign/pattern"
#folder_genome = "D:/Data/Matthias Schade/workspace/VirusProbeDesign/genome"

#folder from which results are read; if input_folder="" then the current working directory is chosen instead
#input_folder = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/mm4/2012-06-05_13-05_19nt"
#input_folder = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/mm4/2012-06-05_13-05_19nt/"
#input_folder = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/APR8 vs dog_ncDNA_hairpinRNA/"
#input_folder = "//TS412-MOLBP/Shared/Matthias Schade/probe design/APR8 vs dog_ncRNA_miRNA/"
#input_folder = "//TS412-MOLBP/Shared/Matthias Schade/probe design/APR8 vs dog_ncRNA_miRNA/2012-06-16_08-34_30nt_08mm_100rr/"

input_folder = "D:\Data\Matthias Schade\workspace\MyTestProject\mynewPythonPackage\2012-07-08_17-29_20nt_04mm_100rr"
#input_folder = "D:/Data/Matthias Schade/workspace/VirusProbeDesign/2012-06-04_12-25_20nt/"
#input_folder = "D:/Eigene Dateien matthias/workspace/MyTestProject/mynewPythonPackage/2012-06-03_22-06_17nt/"

#Filter: name-ending of files containing original qgrams:
filter_qgramfileFA = "_qgrams.fa"
#filter_qgramfileFA = "_qgrams.fa"

#Filter: name-ending of files containing results of razerS-alignment (where pattern matches with target genome):
filter_results = ".result"


#Analysis saving name
fname_pPP = "pPP"
picForm = ".dat"

#output file with found sequences:
outFA = "SequencesFound"
outForm = ".fa"

#Shelve file name for loading all variables from output-folder
shlv_name = "shelved.out" #taken from: http://stackoverflow.com/questions/2960864/how-can-i-save-all-the-variables-in-the-current-python-session

#Segs: 1=PB2(2300), 2=PB1(2300), 3=PA(2193), 4=HA(1723), 5=NP(1501), 6=NA(1373), 7=MP(986), 8=NS(848)
seg_length={"seg1": 2300, "seg2":2300, "seg3":2193, "seg4":1723, "seg5":1501, "seg6" :1373, "seg7":986, "seg8":848 } #reference segment length

#Allow code to be run in two modi: 
#    either all sequences found by razerS will be kept ('false')
#    or all sequences foudn by razerS will be considered negative hits, such that they will be cleaned from 
#     the entire qGram-Lists and the remaining hits will be the qGram-Entries which did not get purged.
bNonMatchFinder = True  #true = primary results will be purged by hits in genome  (=> inversion of results)
                        #false = primary hits in genome will be considered hits   (=> keeping of results)

#(Dis/)Enable checking the resulting sequences via BLAST against an organism:
bResultCheckViaNCBI = True

#number of results shown on the screen for each BLAST-query: (only executed for: bbResultCheckViaNCBI=True)
# when <1 then no results are shown on screen.
# this option has no(!) influence on what is being saved or not
nResultCheckViaNCBIVisualize= 0

# verbose-modus: 
bVerbose = True

# NCBI-BLAST
# for help see: help(NCBIWWW.qblast) #requires: from Bio.Blast import NCBIWWW
#Entrez.email = "matthiasschade.de@googlemail.com" #necessary??? (only executed for: bbResultCheckViaNCBI=True)

#Entry Query: any limitations as to what range of organisms, etc to look at only
# check details: http://www.ncbi.nlm.nih.gov/books/NBK3837/
#BLAST_orgn="Canis familiaris[orgn]" or #(only executed for: bResultCheckViaNCBI=True)
#BLAST_orgn="Canis familiaris" #(only executed for: bResultCheckViaNCBI=True)
###BLAST_orgn="Canis familiaris (taxid:9615)" #NOTE: fails with taxid and name
#BLAST_orgn="Canis familiaris (taxid:9615) OR Homo sapiens (taxid:9606)" #(only executed for: bResultCheckViaNCBI=True)
##BLAST_orgn="Canis familiaris OR Homo sapiens" #(only executed for: bResultCheckViaNCBI=True)
##BLAST_orgn="(taxid:9615) OR (taxid:9606)" #(only executed for: bResultCheckViaNCBI=True)
#BLAST_orgn="9615 OR 9606" #(only executed for: bResultCheckViaNCBI=True)
###Mus musculus[organism] AND biomol_mrna[properties]
BLAST_orgn="Canis familiaris[organism] OR Homo sapiens[organism]" #(only executed for: bResultCheckViaNCBI=True)

  
#BLAST-algorithm used (only executed for: bResultCheckViaNCBI=True)
BLAST_algr = "blastn"

#BLAST-database used (only executed for: bResultCheckViaNCBI=True)
#    large: "nt", "genbank", 
#    dog: "9615_genomic" (dog genomic), "dog_9615" (SNP database for dog),
#    human: "9606_genomic" (human genomic)
#    BLAST_db = "wgs" #whole-genome shotgun contigs:
#    BLAST_db = "nt" #not registered in http://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=ProgSelectionGuide#db
BLAST_db = "nr"

#

#Histlist_size returned by blast from query (only executed for: bResultCheckViaNCBI=True)
qHitSize = 20

#required minimum identity for BLAST-verification hit to be returned (only executed for: bResultCheckViaNCBI=True)
#ident #qPerIdent = 90

#Rejection criterion: how many mismatches allowed
#nMM = 2 

#query-result filenames for saving: output format will be ['results_file'####.xml] (only executed for: bResultCheckViaNCBI=True)
results_file = "test"

#Maximum OS-dependent length of filename (only executed for: bResultCheckViaNCBI=True)
maxFileLen=100

#add a delay in between two queries to the internet-database (only executed for: bResultCheckViaNCBI=True)
queryDelay=1 #sleeps for x seconds

#TestStrings
testBLAST_ExpectPositive = "GTTAATGTAGCTTAATTA" #this string must result in a perfect match!!! [choose your own!]
testBLAST_ExpectNegative = "GGATTCGAACCGAACGGC" #this string must result in very bad match!!! [choose your own!]




def create_qgramIndex_list(allfiles, input_folder,myFileFilter):
    #qgramindexlist=[]
    qgramindexlist={}
    m=0
    #User feedback
    print "\nSTARTING: Creation of qgramIndexList for all source patterns ..."
    #get a list of all files in the current working directory of python
    #allfiles = listdir(os.getcwd())

    for myFile in allfiles:
        #consider only those files which end the filter-string specified
        print "myFile: ", myFile
        print "test, if endwith: ", myFileFilter
        #if not myFile.endswith(filter_qgramfileFA): continue
        if not myFile.endswith(myFileFilter): continue
        
        print "yes, huerde genommen"
        #open each file as "read only"
        
        myFilePath = join(input_folder, myFile)
        print " opening: ", myFilePath
        with open(myFilePath, "r") as f:
            m=m+1
            #print "reading in ", myFile
            for line in f:
                #print "length: ", len(qgramindexlist)
                #in each file and each line get the first 'word' only 
                #print "linsplit: ", line.split()
                firstword = line.split()[0]
                #print "firstword: ", firstword
                #print "firstword[ohne ersten Buchstaben]: ", firstword[1:]
                #
                if firstword[0]==">":
                    strPos = firstword[1:] #Zwischenspreichern
                else:
                    strSeq = firstword[:] #Zwischenspeichern
                    #print len(qgramindexlist)
                    #print "strPos: ", strPos, "strSeq: ", strSeq
                    #qgramindexlist.append((strPos, strSeq))
                    qgramindexlist[strPos] = strSeq
                    strPos=""
                    strSeq=""
    print " DONE: qgramIndexList completed for "+str(m)+" file(s), containing a total of " + str(len(qgramindexlist)) +" elements."
    return qgramindexlist

def stripSegPosFromEnhancedFASTAFormat(d):
    #Function needed when razerS-output format was set with flag "-of 1": enhanced FASTA output
    # INPUT:
    #    str: a string of this example-format: ">30,10[id=seg7(00175:00195)_0,fragId=175,contigId=ENSCAFT00000042114,errors=3,percId=85,ambiguity=1]\n sequence"
    #OUTPUT:
    #    d: a string of this format type "<inputpatternfilename>(nt-pos:nt-pos)"
    
    toFind1 = "id=" #pre-fix of the substring we are looking for
    toFind2=",fragId=" #inexact suffic of the substring we are looking for
    toFind3="_" #inexact suffix of the substring we are looking for (might exist in substring as well)
    
    #get starting position of substring
    n1 = d.find(toFind1)+3
    
    #get first approx for ending position of substring
    n2 = d.find(toFind2)
    
    #refine ending position of substring
    #print "zwischenresult: " + d[n1:n2]
    almost=d[n1:n2]
    n3 = almost.rfind(toFind3)
    #print "n3: ", n3
    #print "result: " + d[n1:n1+n3]
    
    return d[n1:n1+n3]

def remove_qGramsByHost(allfiles,input_folder, qGramIndexKeys, razerSOutputFormat, bVerbose):
    '''
    Removes all qgrams from qGramIndexKeys which were found to also exist in the host genome
    by parameters (identity, rr) specified for razerS
      - qGramIndexKeys = ['seg1(0001:0020)', ...]
    '''
    
    nInitial = len(qGramIndexKeys)
    
    #------------------------#
    #User feedback
    #------------------------#
    if bVerbose:
        print "\nSTARTING: Removal of qgrams which were found to also exist in the host genome. \n\t  Starting with "+str(nInitial)+" qgrams created from input pattern (or: remaining qgrams)..."
    resultsIndexKeys=[]
    for myFile in allfiles:
        #consider only those files which end the filter-string specified
        if not myFile.endswith(filter_results): continue
        #open each file as "read only"
        myFilePath = join(input_folder, myFile)
        with open(myFilePath, "r") as f:
            #print "reading in ", myFile
            for line in f:
                #get the first 'word' only 
                firstword = line.split()[0]
                if (razerSOutputFormat=="of0"): #default razerS output format: ">header \n sequence"
                    #ignore comments which appear, when for the output of razerS the flag "-a" was set
                    if firstword[0]!="#": #attention: here was a 1 !!!!!
                        resultsIndexKeys.append(firstword)
                if (razerSOutputFormat=="of1"): #enhanced FASTA format of razerS output: ">30,10[id=seg7(00175:00195)_0,fragId=175,contigId=ENSCAFT00000042114,errors=3,percId=85,ambiguity=1]\n sequence"
                    #print "firstword: " + str(firstword)
                    #print "firstword[0]: " + str(firstword[0])
                    if firstword[0]==">":
                        #raus=stripSegPosFromEnhancedFASTAFormat(firstword)
                        #print "raus: " + str(raus)
                        resultsIndexKeys.append(stripSegPosFromEnhancedFASTAFormat(firstword))
            #print "\t\t\t preparing razerS-results (=negative list), extending to "+str(len(resultsIndexKeys))+" entries..."      
    
    #reduce results down to unique entries
    if bVerbose:
        print "\t  RazerS found "+str(len(resultsIndexKeys))+" hits of pattern in the genome. Reducing multiple hits to unique hits..."
    #print "\t  reducing "+str(len(resultsIndexKeys))+" razerS-results down to unique entries ..."
    resultSet = set(resultsIndexKeys)
    
    #remove sequences from the qgramindex, leaving only those sequences for which raszers did not return a match between virus and host-genome
    if bVerbose:    
        print "\t  Removing "+str(len(resultSet))+" unique razerS-hits from the initial "+str(nInitial)+" pattern-generated (or: remaining) qgrams ..."
    
    #print"\n qGramIndexKeys vorher: ", qGramIndexKeys
    #print"\n resultSet vorher: ", resultSet
    
    qGramIndexKeys = qGramIndexKeys-resultSet
    if bVerbose:
        print "\n\n"
    #print "qgramindexlist after: ", len(qGramIndexKeys)

    #------------------------#
    #User feedback
    #------------------------#  
    nEnd = len(qGramIndexKeys)
    #print " DONE: "+str(nInitial-nEnd)+" qgrams removed, leaving "+str(nEnd)+" qgrams."
    if bVerbose:
        if nEnd>0:
            print " DONE: "+str(nEnd)+" qgrams as possible probes identified!"
        else:
            print " DONE: no possible probes found! Try a longer sequence or a lower minimum edit-distance between pattern and (host-) genome!"
    
    return list(qGramIndexKeys)


def find_key(dic, val):
    """return the key of dictionary dic given the value"""
    #COMMENT: actually, positive case (existance of multiples) never tested!!!!
    return [k for k, v in dic.iteritems() if v == val][0]


def get_multipleHitsInPattern(qGramIndexDict):
    #COMMENT: actually, positive case (existance of multiples) never tested!!!!
    multiSeqPos=[]
    print "\nSTARTING: Checking for sequence-doubles or -multiples in source pattern."
    #extract all sequences from dict
    seqList = qGramIndexDict.values()
    if len(seqList)> len(set(seqList)):
        print "\tSequence-doubles or -multiples found. Extracting sequences ..."
        #create statistic on occurrences of values in list
        y=collections.Counter(seqList)
        #sequences, which occur more than once
        multiSeqs = [i for i in y if y[i]>1]
        print "\t " +str(len(multiSeqs))+" sequences occur more than once."
        #Positions of sequences which occur more than once
        #multiSeqPos = [j in qGramIndexDict ]
        multiSeqPos = find_key(qGramIndexDict, multiSeqs)
        print "\t Corresponding positions: ",  multiSeqPos
    else:
        print " DONE: No sequence-doubles or -multiples found."    

    return multiSeqPos




def get2DArrayOfNonHitsInTargetGenome(qGramIndexDict,input_folder):
    #DESCIPTION: returns a 2D-array: for each source pattern the is a list of non-hits
    # e.g.: {[segment1: (452, 578, 323, 676)], [segment4: (2, 676)]}
    
    positiveProbePositions = {}
    
    #Read in all files in the patter directory
    #patternfiles = listdir(folder_pattern)
    patternfiles = listdir(input_folder)
    #_qgrams.fa
    #print "patternfiles", patternfiles
    
    #strip file-type ending
    #patternFileNames = [x[:-3] for x in patternfiles: if not x.endswith(".fa"): continue] 
    pFN=[]
    for x in patternfiles: #TODO: pythonic!!!!
        if x.endswith(filter_qgramfileFA): #TODO: pythonic!!!!
            #pFN.append(x[:-len(filter_qgramfileFA)]) #TODO: pythonic!!!!
            pFN.append(x[:4]) #TODO: pythonic!!!!
    patternFileNames = pFN #TODO: pythonic!!!!
    
    ##        if not resultfile.endswith(".result"): continue
    #print "patternfileNames: ", patternFileNames
    
    #print "-----PATTTERN FILE NAMES\n"
    #print patternFileNames
    
    #------------------------#
    #User feedback
    #------------------------#
    print "\nSTARTING: extracting probe-starting-positions relative to source pattern for each source pattern."
    #print "len(qGramIndexDict): ", len(qGramIndexDict)
    for p in patternFileNames:
        miniSeqP = []
        
        
        for q in qGramIndexDict:
            #print "q: ", q
            #print "patternfileNames: ", p
            #print "q.find(patternfileNames): ", q.find(p)
            
            #print "p: ", p, " and q: ", q
            #print "q.find(p)", q.find(p)
            
            #only if the pattern name can be identified:
            if (q.find(p)>-1):
                #get the sequence position, which is walled in between "(" and ":":
                mySubString=q[q.find("(")+1:q.find(":")]
                #append position
                miniSeqP.append(int(mySubString))
                #print "mySubString: ", mySubString
                
                #print str(q(srt:end))
                #seqPosition.append(int(q(srt:end)))
        #flush sequence positions into larger "array"
        miniSeqP.sort()
        
        positiveProbePositions[p]=miniSeqP
    
    print " DONE: extracting probe starting positions."
    
    return positiveProbePositions

def loadpPP(fname,picForm):
    #DESCRIPTION:
    #    load settings as a pickle from a specified filename
    print "STARTING: loading pPP"
    pPP ={}
    try:
        fileobj = open(fname+picForm,'r')
        pPP = pickle.load(fileobj)
        fileobj.close()
    except Exception:
        print " ERROR: loading results failed."
    print " DONE: loading pPP"
    return pPP

def savepPP(pPP,input_folder, fname, picForm):
    #DESCRIPTION: store settings as a pickle under a specified filename
    print "\nSTARTING: saving results"
    fname = join(input_folder, fname)
    try:
        fileobj = open (fname+picForm,'w')
        success = pickle.dump(pPP,fileobj)
        fileobj.close()
    except Exception:
        print " ERROR: saving results failed."
    
    print " DONE: Results saved as: "+ fname
    
    return success

def visualizepositiveProbePositions(pPP, q, mm, rr, ident):
    
    #error check
    if not type(pPP) is dict:
        print " Input not of type dict"
        return
    
    #User-feedback
    print "\nSTARTING: visualization"
    
    #number of columns and rows for subplot
    plot_cols = 2
    l = len(pPP)
    plot_lins = int(math.ceil(l/plot_cols))
    
    #get screen width and height
    root = Tkinter.Tk()
    screen_width = root.winfo_screenwidth()
    screen_height = root.winfo_screenheight()
    
    #run through all output lines in positivePatternPositions (pPP):
    figFlag=0
    ax=[]
    c=0
    for o in pPP:
        c=c+1 # counter for subplot
        
        #jump to the next segment, if this one is empty
        #if not pPP[o]:
            #print "will continue" 
            #continue
        
        x=pPP[o]
        y=[]
        xLim=[0,2500]
        yLim=[0.9,1.1]
        #create a y for every x
        y = [1 for i in x]
        #for i in x: #y =[1 for i in x] more pythonic????
        #    y.append(1)
        #print "\nSegment: ", o
        #print "Data: ", y
        
        #create a figure once (only once, so set a flag!) into which subplots are projected
        if figFlag==0: 
            #fig = PLT.figure() #creates a new fig
            fig = PLT.figure(figsize=(14, 14)) #creates a new canvas with width, height in inches
            #fig = PLT.figure(figsize=(screen_width, screen_height)) #creates a new canvas with width, height in inches
            str_title = "APR8 sequence starting positions for probe with "+str(q)+" nt length at an edit distance of "+str(mm+1)+ " (ident="+str(ident)+") or higher against the tested genome"
            
            #differentiate between match/ and non-match finding
            if bNonMatchFinder:
                str_title = "NonMatchFinder: " + str_title
            else:
                str_title = "MatchFinder: " + str_title
            fig.suptitle(str_title)
            figFlag=1
        
        #--------------------------------------------
        #create a subplot:
        #--------------------------------------------
        #matplotlib.pyplot.subplots(nrows=1, ncols=1, sharex=False, sharey=False, squeeze=True, subplot_kw=None, **fig_kw)
        #sharex : bool
        # If True, the X axis will be shared amongst all subplots. If True and you have multiple rows, the x tick labels on all but the last row of plots will have visible set to False
        #sharey : bool
        # If True, the Y axis will be shared amongst all subplots. If True and you have multiple columns, the y tick labels on all but the first column of plots will have visible set to False
        
        sollPos = re.findall(r'\d+', o) #extract integers from key-name for correct positioning        
        if sollPos:
            #print sollPos
            if int(sollPos[0])>0:
                ax.append(fig.add_subplot(420+int(sollPos[0]))) #211
        else:
            ax.append(fig.add_subplot(420+c)) #211
            
        ax[len(ax)-1].scatter(x,y, marker='+')#edgecolors='none', alpha=0.2)
        ax[len(ax)-1].set_xlim(xLim)
        ax[len(ax)-1].set_ylim(yLim)
        ax[len(ax)-1].set_title(o)

        
        #Visualize density distribution (normed to 1) of positive sequences
        if len(y)>1:
            x[0]=x[0]*1.0001 #attention: multiplicator needed ... otherwise no conversion from int to float thus causing the density estimation to fail
            density = gaussian_kde(x) #density = scipy.stats.kde.gaussian_kde(x)
            density.covariance_factor = lambda : 0.05
            density._compute_covariance()
            xg = np.arange(0., max(xLim), 1) #0.1
            denMax=max(density(xg))
            #ax[len(ax)-1].plot(xg, density(xg)/denMax, 'k:', alpha=0.3) #alpha=0.1
            ax[len(ax)-1].plot(xg, density(xg)* ((max(yLim)-min(yLim))/denMax) + min(yLim), 'k:', alpha=0.3) # shift density curvoonto min-displayed
        
        #Create a text-insert:
        font = "sans-serif"
        ax[len(ax)-1].text(max(xLim)*0.85,max(yLim)*0.95, str(len(x))+" seqs", ha="center", family=font, size=14)
        
        if sollPos:
            #print sollPos
            if int(sollPos[0])>0:
                #symbolysing segment length: draw a green box that spans the y-axis
                #ax[len(ax)-1].axvspan(1.25, 1.55, facecolor='g', alpha=0.5)
                ax[len(ax)-1].axvspan(0, seg_length[o], facecolor='g', alpha=0.1)
                #seg_length
    
    # show the plot on the screen
    #PLT.show()
    
    
    #save plot in input_folder
    strSaveFig = join(input_folder, 'output_img.png')
    PLT.savefig(strSaveFig)
    print " saving plot in ", strSaveFig
    
    #User Feedback
    print " DONE: visualization\n"
    return

def extract(d, keys):
    # from Trent Mick: http://code.activestate.com/recipes/115417-subset-of-a-dictionary/
    return dict((k, d[k]) for k in keys if k in d)
    #return dict((d[k], k) for k in keys if k in d)

def getUserFolder(str_iniDir, strDialog):
    if not str_iniDir:
        str_iniDir = os.getcwd()
        print "hihi"
    master = Tkinter.Tk()
    master.withdraw() #hiding tkinter window
    #"Open pattern directory"
    #file_path = tkFileDialog.askopenfilename(initialdir=folder_pattern, title="Open pattern file", filetypes=[("txt file",".txt"),("All files",".*")])
    file_path = tkFileDialog.askdirectory(initialdir=str_iniDir, title=strDialog, mustexist=True)
     
    if file_path != "":
        #print "you chose file with path:", file_path
        str_Return = file_path
    else:
        #print "you didn't open anything!"
        str_Return = str_iniDir
     
    master.quit()
    return str_Return

def purgeByGenome(input_folder, allfiles, qGramIndexDict,razerSOutputFormat, bVerbose):
    #this function reduces entries in qGramIndexDict by sequences found in allfiles,
    # such that only those entries in qGramIndexDict remain which were not named/found in allfiles in folder input_folder
    
    #extract only the sequence names (thereby ignoring the sequences) and reduce it to unique entries (probably unnecessary)
    #   qGramIndexDict = {'seg1(01220:01233)': 'TCAGAATGAGTTT', 'seg1(00391:00404)': 'ATCTGGAAAAGGC', ...}
    
    #print "auszug qGramIndexDict ganz am Anfang: ", qGramIndexDict
    #print "in purgeBy .. qGramIndexDict.keys :", qGramIndexDict.keys()
    #print "in purgeBy .. qGramIndexDict.values :", qGramIndexDict.values()
    
    qGramIndexKeys = set(qGramIndexDict.keys()) #qGramIndexListOnly = [qGramIndexListWithSeq[i][0] for i in range(0, len(qGramIndexListWithSeq) -1)]
    #print "in purgeBy .. qGramIndexKeys:", qGramIndexKeys    
    
    #print"\n qGramIndexVolues vorher: ", qGramIndexDict.values()
    #print"\n len(set(qGramIndexVolues)) vorher: ", len(set(qGramIndexDict.values))
    
    #from qGramIndexKeys remove all entries which have also been found to exist in the target-genome
    # so 'qGramIndexKeys_purged' only contains suitable positive probe target sequences
    # output: qGramIndexKeys_purged = ['seg(00608:00621), 'seg(00618:00631)', ...]
    qGramIndexKeys_purged = remove_qGramsByHost(allfiles, input_folder, qGramIndexKeys,razerSOutputFormat, bVerbose)
    
    
    #reduce dict down to the remaining suitable probe-target sequences
    #print "to be: qGramIndexDict: ", qGramIndexDict
    #print "to be: qGramIndexKeys_purged: ", qGramIndexKeys_purged
    
    qGramPositiveIndex = extract(qGramIndexDict, qGramIndexKeys_purged) #TODO: 20->19 reverse!!!
    #print "ganz nah dran: qGramPositiveIndex", qGramPositiveIndex
    return qGramPositiveIndex

def getShelvedData(input_folder, shlv_name):
    # Retrieving Objects from a Shelve File and thereby overriding current global variables
    
    #Variables to load from shelve-file: initialized in case shelve-file failed to load
    v = -1  #default-value
    #bNonMatchFinder = True #default-value: ATTENTION: IMPORTANT
    bReduceSeqAtRuntime=False #default-value
    mm=-1 #default-value
    rr=-1 #default-value
    q=-1    #default-value
    ident=-1#default-value
    razers_arg = [] #default-value
    bInDelAsError=False #new in v=0.63
    strErrFile="" #new in v=0.63

    patternfiles = [] #default-value
    genomefiles = [] #default-value
    razerSOutputFormat="of1" #irregular default-value #should be "of0" for usual razerS-output see: "razerS -h"
    
    shelve_file = join(input_folder, shlv_name)
    if os.path.exists(shelve_file):
        print "\nSTARTING to load variables from shelve-file: ", shelve_file
        my_shelve = shelve.open(shelve_file, "r")            
        if len(my_shelve) > 0:
            v = my_shelve['v'] #get version number
            #bNonMatchFinder = my_shelve['bNonMatchFinder'] #get search-modus (finding positives or negatives)
            bReduceSeqAtRuntime = my_shelve['bReduceSeqAtRuntime'] #get speed-modus (irrelevant for this code)
            mm = my_shelve['mm'] #get number of mismatches
            rr = my_shelve['rr'] # get recognition-ration for checking against genome
            q = my_shelve['q'] # get probe length tested
            ident = my_shelve['ident']
            razers_arg = my_shelve['razers_arg']
            try:
                razerSOutputFormat = my_shelve['razerSOutputFormat'] #new in v=0.6
                bInDelAsError = my_shelve['bInDelAsError'] #new in v=0.63
                strErrFile = my_shelve['strErrFile'] #new in v=0.63
                patternfiles = my_shelve['patternfiles'] # original list of pattern files used # WHY DONT THESE LOAD???
                genomefiles = my_shelve['genomefiles'] # original list of genome files used # WHY DONT THESE LOAD???
            except Exception: 
                print " exception thrown and passed"
                pass
            print " DONE: Variables loaded successfully from shelve file"
        else:
            print " DONE: No variables loaded from shelve file; continuing with default values"
        my_shelve.close()
    else:
        print " No shelve-file found, thus no variables loaded from shelve file; continuing with default values"
    #return v, q, bNonMatchFinder, bReduceSeqAtRuntime, mm, rr, q, ident, razers_arg, razerSOutputFormat, bInDelAsError, strErrFile, patternfiles, genomefiles
    return v, q, bReduceSeqAtRuntime, mm, rr, q, ident, razers_arg, razerSOutputFormat, bInDelAsError, strErrFile, patternfiles, genomefiles
           
def createFoundSequenceFileFA(di,folder, FName):
    #INPUT
    #    di: dictionary {seq_name: sequence}
    #    folder: working folder for results to be saved in
    #    FName: file name (e.g. "sequencesfound.fa")
    
    # sort by key, such that a sorted file is created
    qGramPosInd = [ (k,di[k]) for k in sorted(di.keys())] ## (k,v) tuples in resulting list
    
    myFile = join(folder, FName)
    readcount = 0
    #open/create file as writable
    with open(myFile, 'w') as f:
        #create one fasta-entry
        #print "type(qGramPosInd): ", type(qGramPosInd)
        for s in qGramPosInd:
            if (type(qGramPosInd)=="dict"):
                f.write(">" + str(s)+"\n")
                f.write(qGramPosInd[s]+"\n")
            else:   #assume "list"
                f.write(">" + str(s[0])+"\n")
                f.write(str(s[1])+"\n")
            readcount += 1
    return myFile

def getBestHSP(blast_records):
    #for the best hit get the number of positive matches
    #return both the best HSP_positive and the number of records checked
    hspMax=0    #best identity hit
    k=0
    try:
        blast_record = blast_records.next()
        for alignment in blast_record.alignments:
            k=k+1 #counts the number of alignments in a record
            m=0
            for hsp in alignment.hsps:
                m=m+1
                #print hsp.positives, k, m
                #get the highest number of common identity letters 
                if hsp.positives>hspMax:
                    hspMax=hsp.positives
    except:
        print "the end of checking for HSP."
    #return
    return [hspMax,k]


def saveBLASTasPlainText(blast_file, E_VALUE_THRESH,nVisualize):
    #INPUT: 
    #    sourceF: full path and file of the source xml-Blast-result-file
    #    E_VALUE_THRESH:
    #    bVisualize: a flag indicating if visualization should occur 
    #
    #OUTPUT: 
    #
    
    nMaxSeq = 75 #maximum length of sequence to be fully saved, everything longer will be cut off
    
    #print "attempting to open: ", sourceF
    #print "does exist?: ", os.path.isfile(sourceF)
    #open xml-parsed-file
    #result_handle = open(sourceF, "r")
    
    
    blast_handle = open(blast_file, "r")
    blast_records = NCBIXML.parse(blast_handle)
    #from Bio.Blast import NCBIStandalone
    #blast_parser = NCBIStandalone.BlastParser()
    #blast_record = blast_parser.parse(blast_handle)

    #check if file exists, if not, create file; finally open file in 'strMod' modus
    #import os.path
    #os.path.isfile(fname)
    
    #create new file name with '.txt' instead of the former ending
    save_file_txt = blast_file[0:-4] + str(".txt")
    
    #print "opening file: FName", save_file_txt
    with open(save_file_txt, 'a') as f:
        
        #print "asdf"
        #print "blast_record", blast_record
        #print "blast_record.alignments ", blast_record.alignments
        #print "type(blast_record): ", type(blast_records)
        
        try:
            blast_record = blast_records.next()
            for alignment in blast_record.alignments:
                cc=0 #counter for visualizing on screen
                for hsp in alignment.hsps:
                    cc=cc+1 #counter for visualizing on screen
                    #if hsp.expect < E_VALUE_THRESH:
                    f.write('****Alignment****\n')
                    f.write('sequence:\\tt' +str(alignment.title) + "\n")
                    f.write('length:\t\t' +str(alignment.length) + "\n")
                    f.write('e value:\t\t' +str(hsp.expect) + "\n")
                    f.write('score:\t\t' +str(hsp.score) + "\n") 
                    #f.write('num_alignments:\t'+str(hsp.num_alignments) + "\n") 
                    f.write('identities:\t'+str(hsp.identities) + "\n")  #The number and fraction of total residues in the HSP which are identical
                    f.write('positives:\t'+str(hsp.positives) + "\n")  #The number and fraction of residues for which the  alignment scores  have positive values.
                    f.write('gaps:\t\t'+str(hsp.gaps) + "\n") 
                    #f.write('strand: '+str(hsp.strand) + "\n") 
                    #f.write('frame: '+str(hsp.frame) + "\n")
                    #f.write('query: '+str(hsp.query) + "\n")
                    f.write(hsp.query[0:nMaxSeq] + '...'+'\n') #Attention: everything
                    f.write(hsp.match[0:nMaxSeq] + '...'+'\n')
                    f.write(hsp.sbjct[0:nMaxSeq] + '...'+'\n')
                    if len(hsp.query)>nMaxSeq+1:
                        f.write('\t##Warning: Query length ('+str(len(hsp.query)+') longer than what has been saved here.\n'))
                    f.write("\n")
                    #User-Feedback: output to screen
                    if (nVisualize+1)>cc:
                        print '\n\t\t****Alignment****'
                        print '\t\tsequence: ', alignment.title
                        print '\t\tlength: ', alignment.length
                        print '\t\te value: ', hsp.expect
                        print '\t\tscore: ', hsp.score
                        #print '\t\tnum_alignments: ', hsp.num_alignments
                        print '\t\tidentities: ', hsp.identities #The number and fraction of total residues in the HSP which are identical
                        print '\t\tpositives: ', hsp.positives #The number and fraction of residues for which the  alignment scores  have positive values.
                        print '\t\tgaps: ', hsp.gaps
                        #print '\t\tstrand: ', hsp.strand
                        #print '\t\tframe: ', hsp.frame
                        #print '\t\tquery: ', hsp.query
                        print '\t\t'+hsp.query[0:75] + '...'
                        print '\t\t'+hsp.match[0:75] + '...'
                        print '\t\t'+hsp.sbjct[0:75] + '...'
                        if len(hsp.query)>nMaxSeq+1:
                            print('\t##Warning: Query length ('+str(len(hsp.query)+') longer than what is being shown here.\n'))
            bsuccess=True
        except:
            print " Verification via BLAST-Query not successfull."
            bsuccess=False
    f.close()

    return bsuccess


def checkFAFileViaBLASTAgainstGenome(BLAST_orgn, BLAST_algr, BLAST_db, mySeq, qHitSize, ident, results_file, maxFileLen, queryDelay, t1start, input_folder, n_now, n_total, mySeqName):
    
    #INPUT:
    #    BLAST_orgn: organism to compare 'mySeq' against (eg.:"Canis familiaris[orgn]") 
    #    BLAST_algr: type of search (eg. blastn)
    #    BLAST_db: type of data (eg. "nt")
    #    mySeq: one sequence or a list of sequences??????????
    #    qHitSize: number of hits to be extracted from the answer of the BLAST-query (e.g.: 2)
    #    qPerIdent: required minimum identity for blast hit to be returned
    #    results_file: query-result filenames for saving: output format will be ['results_file'####.xml]
    #    maxFileLen: Maximum length of filename (OS-dependent)
    #    pickle_file: name of file for dumping results as pickle
    #    queryDelay: add a delay in between two queries to the internet-database (
    #    t1start:
    #
    # inspired by: http://scienceoss.com/run-blast-from-biopython/
    #
        
    #User-Feedback    
    if n_now==1:
        print '-------------------------------------------------------------'
        if n_now==1:
            print ' Checking Results by blasting them via NCBI-BLAST  '
        if n_now==0:
            print ' Testrun:  '
        print '-------------------------------------------------------------'
        print
        print 'Input-Parameters'
        print '\tBLAST-Parameters: ', BLAST_algr, BLAST_db, qHitSize, ident, BLAST_orgn
        #print '\tVirus-Genome-Parameters: ', seq_v_file, len(rng_v)
        print '\tProbe-Length (nt): ', len(mySeq)
   
    
    if mySeq:
        nProbeLen = len(mySeq)
        #print "nProbeLen: ", nProbeLen
    else:
        nProbeLen = 0
        print "WARNING: no nProbeLength given"
    
    #User-Feedback:
    print "\t"+str(datetime.datetime.now()), '- - ('+str(n_now)+'/'+str(n_total)+'): Query with(h=', qHitSize, 'i=', ident, ') started for', len(mySeq), 'nt-long sequence: ', mySeq
    
    #QUERY
    #    result_handle = NCBIWWW.qblast("blastn", "nt", q, hitlist_size=5, perc_ident=50, megablast=True, entrez_query="Canis familiaris[orgn]")
    #    result_handle = NCBIWWW.qblast("blastn", "nt", ["ACCCTG", "ACTTCTG"], entrez_query="Canis familiaris[orgn]")
    #    result_handle = NCBIWWW.qblast("blastn", "nt", q)
    result_handle = NCBIWWW.qblast(BLAST_algr, BLAST_db, mySeq, hitlist_size=qHitSize, perc_ident=ident, entrez_query=BLAST_orgn)
    
    #create name for saving query-results:
    now = datetime.datetime.now()
    if len(mySeq) < maxFileLen:
        saveFName = mySeqName+"_"+str(mySeq + "_vs_" + str(BLAST_db) + "__"+now.strftime("%Y-%m-%d_%H-%M") + ".xml")
    else:
        saveFName = mySeqName+"_"+str(results_file + "__"+now.strftime("%Y-%m-%d_%H-%M") + ".xml")
    blast_file = join(input_folder,saveFName.replace(":", "-")) #remove ':' from file name

    #saving query-results as xml
    save_file = open(blast_file, "w") #save_file = open("my_blast.xml", "w")
    save_file.write(result_handle.read())
    save_file.close() #close handle for results
    result_handle.close()
    
    #Save Results as Plain Text
    bSavingSuccessfull = saveBLASTasPlainText(blast_file, 1, nResultCheckViaNCBIVisualize)

    #Parse Results
    #result_handle.seek(0) # rewind result_handle back to the beginning
    blast_handle = open(blast_file, "r")
    blast_records = NCBIXML.parse(blast_handle)
    
    #for the best hit get the number of positive matches
    [hspMax, k] = getBestHSP(blast_records)
    #print "type(blast_record) 2: ", type(blast_records)
    #print "hspMax: ", hspMax
    #print "k: ", k
    
    #User-Feedback
    if k > 0:
        if bNonMatchFinder:
            print "\t"+str(datetime.datetime.now()), '- -     ... resulting in ', k, '/', qHitSize, 'records with partial predicted hybridization with target genome. Best matching-identity of', hspMax, '/', nProbeLen
        else:
            print "\t"+str(datetime.datetime.now()), '- -     ... TODO-correct OUTPUT FOR USER....resulting in ', k, '/', qHitSize, 'records fulfilling the requirements with best matching-identity of', hspMax, '/', nProbeLen #TODO correct output for user
    else:
        if bNonMatchFinder:
            print "\t"+str(datetime.datetime.now()), '- -     ... resulting in 0 sequences matching the target genome, meaning: this sequence is predicted not to hybridize with any sequence from the specified database.'
        else:
            print "\t"+str(datetime.datetime.now()), '- -     ... TODO-correct OUTPUT FOR USER....resulting in 0 records fulfilling the requirements, meaning: this sequence is predicted 100% hybridize a sequence from the specified database.' #TODO correct output for user


    #Calculate missmatch-number
    if k > 0:
        mm = nProbeLen - hspMax # nProbeLen = q?????
    else:
        mm = 0



    #Save the direct results of the BLAST-query into file    
    #Create a filename for results of the current sequence
#    if n_now<>0:
#        now = datetime.datetime.now()
#        if len(mySeq) < maxFileLen:
#            saveFName = mySeqName+"_"+str(mySeq + "_vs_" + "__"+str(BLAST_db) + now.strftime("%Y-%m-%d_%H-%M") + ".xml")
#        else:
#            saveFName = mySeqName+"_"+str(results_file + "__"+now.strftime("%Y-%m-%d_%H-%M") + ".xml")
#        saveFName = saveFName.replace(":", "-") #remove ':' from file name
#
#        #save as xml output
#        save_file = open(join(input_folder, saveFName), "w") #save_file = open("my_blast.xml", "w")
#        blast_records = NCBIXML.parse(result_handle)
#        #result_handle.seek(0) # rewind result_handle back to the beginning
#        save_file.write(blast_records.read())
#        save_file.close() #close handle for results
#                
#        #save a plain text file:
#        #save_file_txt = save_file[0:-4] + str(".txt") 
#        bVisualize=True
#        #bSavingSuccessfull = saveBLASTasPlainText(blast_records_copy,1, join(input_folder, save_file_txt), bVisualize)
#        bSavingSuccessfull = saveBLASTasPlainText(join(input_folder, saveFName), 1, bVisualize)
#        
#    else:
#        saveFName=""
    

    #User-Feedback on Results if this is the last one
#    if cond1 == 'val1' and \
#     cond2 == 'val2' and \
#     cond3 == 'val3' and \
#     cond4 == 'val4':
#      do_something
    if n_now == n_total and \
        n_now>0         and \
        bSavingSuccessfull:
        #print "n_now "+str(n_now)+" ; n_total "+str(n_total)+" bSavingSuccessfull "+str(bSavingSuccessfull)
        #print "\n"
        print '--------------------------------------------------'
        print 'Total Runtime for',n_total,'queries: ', datetime.datetime.now()-t1start
        print '--------------------------------------------------'
        print
        print 'Input-Parameters'
        print '    BLAST-Parameters: ', BLAST_algr, BLAST_db, qHitSize, ident, BLAST_orgn
        #print '    Virus-Genome-Parameters: ', seq_v_file, len(rng_v)
        print '    Probe-Length (nt): ', len(mySeq)
        print

    
    #Create output dic with
    #    "sequence: occurences in virusgenome, lowest mismatch in hostgenome, results-filename"
    #resultsLs[mySeq] = [qdict[mySeq], mm, saveFName]
    return [mySeq, mm, saveFName]    

#---------------------------------------------#
# MAIN CODE
#---------------------------------------------#
if __name__=="__main__":
    
    #------------------------#
    #User feedback
    #------------------------#
    if bNonMatchFinder:
        print "\n--------------------------------\n   WELCOME to non-match-finder\n--------------------------------\n"
    else:
        print "\n--------------------------------\n   WELCOME to     match-finder\n--------------------------------\n"

    #get Folder to be processed/analysed from user
    input_folder = getUserFolder(input_folder, "Open input folder")
    
    # Retrieving Objects from a Shelve File and thereby overriding current global variables
    v, q, bReduceSeqAtRuntime, mm, rr, q, ident, razers_arg, razerSOutputFormat, bInDelAsError, strErrFile, patternfiles, genomefiles = getShelvedData(input_folder, shlv_name)
    
    #get a list of all files in the current working directory of python
    allfiles = listdir(input_folder) #alternative: os.getcwd()
    
    #create a full list of all qgrams of all input-patterns
    qGramIndexDict = create_qgramIndex_list(allfiles,input_folder,filter_qgramfileFA)
    
    #optionally purge 
    if bNonMatchFinder:    
        qGramPositiveIndex = purgeByGenome(input_folder, allfiles, qGramIndexDict,razerSOutputFormat, bVerbose)
    else:
        qGramPositiveIndex = qGramIndexDict
        print "\nComment: no purging of razerS results took place"
    
    #check if the current qGramIndexDict contains the same sequence twice
    multipleHitsInPattern = get_multipleHitsInPattern(qGramPositiveIndex)

    #write an FASTA-output file
    myF = outFA + str("_%03d_nt" %q)+str("_%03d_mm" %mm)+str("_%03d_rr" %rr)+outForm
    outputFA = createFoundSequenceFileFA(qGramPositiveIndex,input_folder, myF)
        
    #get 2D-array of non-hits for each source pattern
    positiveProbePositions = get2DArrayOfNonHitsInTargetGenome(qGramPositiveIndex,input_folder)    
        
    #saving Results before attempting to visualize them
    myF_pPP = fname_pPP + str("_%03d_nt" %q)+str("_%03d_mm" %mm)+str("_%03d_rr" %rr)
    savepPP(positiveProbePositions, input_folder, myF_pPP, picForm)
    
    #create scatter plots for each segment
    visualizepositiveProbePositions(positiveProbePositions, q, mm, rr, ident)
    
    ident=50 #TODO 
    #Check resulting sequences in 'qGramPositiveIndex' via BLAST against an organism:
    if bResultCheckViaNCBI:
       
        i=0
        t1start = datetime.datetime.now() #track time consumption
        for myKey in qGramPositiveIndex:
            i=i+1
            #print datetime.datetime.now(), '- - ('+str(i)+'/'+str(len(qGramPositiveIndex))+'): Query with(h=', qHitSize, 'i=', ident, ') started for', len(qGramPositiveIndex[myKey]), 'nt-long sequence: ', qGramPositiveIndex[myKey]
            #try:
            [mySeq, BLASTmm, saveFName] = checkFAFileViaBLASTAgainstGenome(BLAST_orgn, BLAST_algr, BLAST_db, qGramPositiveIndex[myKey], qHitSize, ident, results_file, maxFileLen, queryDelay, t1start, input_folder, i, len(qGramPositiveIndex), myKey)
            #exception??
            #catch:
                #user feedback: failed to BLAST-check sequence ...
                #write in info-file: failed failed to BLAST-check sequence ...
        
        #Save resultsLs
        #file = open("pickle.pck", "w") # write mode
        #filePCK = open(str(pickle_file)+"_"+str(len(positiveProbePositions[0]))+"nts.pck", "w") # write mode
        #pickle.dump(resultsLs, filePCK)
        
        #Test BLAST-search:
        #Expecting positive results using Teststring named 'testBLAST_ExpectPositive'
        checkFAFileViaBLASTAgainstGenome(BLAST_orgn, BLAST_algr, BLAST_db, testBLAST_ExpectPositive, qHitSize, ident, results_file, maxFileLen, 0, t1start, input_folder, 0, 0, "posTest")
        #Expecting negative results using Teststring named 'testBLAST_ExpectNegative'
        checkFAFileViaBLASTAgainstGenome(BLAST_orgn, BLAST_algr, BLAST_db, testBLAST_ExpectNegative, qHitSize, ident, results_file, maxFileLen, 0, t1start, input_folder, 0, 0, "negTest")
    else:
        print "Variable/flag for checking results via NCBI-BLAST had not been activated."
    
    print "\n-----------------------------------"
    print " Results saved in folder: " + str(input_folder)
    print "-----------------------------------"
    print "\n\n job done"
    
### sort by key
#>>> [ (k,di[k]) for k in sorted(di.keys())] ## (k,v) tuples in resulting list
#[('a', 'any'), ('b', 'both'), ('c', 'cdr'), ('d', 'dec'), ('e', 'egbdf')]
#
#>>> [ di[k] for k in sorted(di.keys())]     ## values only in resulting list
#['any', 'both', 'cdr', 'dec', 'egbdf']
#
### sort by value (there is no elegant way to get the key from the value)
#>>> [ k for k in sorted(di.values())]       ## values (sorted) only in result
#['any', 'both', 'cdr', 'dec', 'egbdf']
